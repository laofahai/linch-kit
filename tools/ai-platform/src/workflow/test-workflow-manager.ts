/**
 * LinchKit æµ‹è¯• AI å·¥ä½œæµç®¡ç†å™¨
 * æ™ºèƒ½æµ‹è¯•ç®¡ç†ã€ç”Ÿæˆå’Œä¼˜åŒ–ç³»ç»Ÿï¼Œä½œä¸º AI å·¥ä½œæµçš„æ ¸å¿ƒç»„ä»¶
 * 
 * @version 1.0.0 - Phase 3 æµ‹è¯•å·¥ä½œæµé›†æˆ
 */

import { createLogger } from '@linch-kit/core'
import { exec } from 'child_process'
import { promisify } from 'util'
import { existsSync, readFileSync, writeFileSync } from 'fs'
import { join, relative } from 'path'

import type { AIProvider } from '../providers/types'
import { createDefaultAIProvider, createAIProviderAdapter } from '../providers/ai-provider-adapter'
import { IntelligentQueryEngine } from '../query/intelligent-query-engine'
import { TestCoverageAnalyzer, type TaskComplexityAnalysis, type CoverageAnalysisResult } from '../query/test-coverage-analyzer'
import { WorkflowStateMachine, WorkflowState } from './workflow-state-machine'
import { 
  TestStrategyDecisionEngine,
  type TestStrategyFactors,
  type StrategyAnalysisContext,
  type TestStrategyDecision
} from './test-strategy-engine'

const execAsync = promisify(exec)
const logger = createLogger('test-workflow-manager')

export interface TestWorkflowContext {
  taskDescription: string
  testType: 'unit' | 'integration' | 'e2e' | 'coverage' | 'ai-generate'
  targetFiles?: string[]
  coverageThreshold?: {
    lines: number
    functions: number
    branches: number
    statements: number
  }
  testStrategy?: 'tdd' | 'bdd' | 'mutation' | 'property-based' | 'traditional' | 'hybrid'
  strategyFactors?: TestStrategyFactors
  analysisContext?: StrategyAnalysisContext
  aiPreferences?: {
    generateMissingTests: boolean
    optimizeExistingTests: boolean
    suggestEdgeCases: boolean
    mockingStrategy: 'manual' | 'auto' | 'hybrid'
  }
}

export interface TestAnalysisResult {
  currentCoverage: {
    lines: number
    functions: number
    branches: number
    statements: number
    files: Record<string, any>
  }
  testGaps: Array<{
    file: string
    uncoveredLines: number[]
    missingFunctions: string[]
    suggestedTests: string[]
  }>
  existingTests: Array<{
    file: string
    testCount: number
    coverage: number
    quality: 'excellent' | 'good' | 'needs_improvement' | 'poor'
    suggestions: string[]
  }>
  recommendations: {
    priority: 'high' | 'medium' | 'low'
    actions: Array<{
      type: 'generate' | 'improve' | 'refactor' | 'remove'
      target: string
      description: string
      effort: 'low' | 'medium' | 'high'
    }>
  }
}

export interface TestGenerationRequest {
  sourceFile: string
  testType: 'unit' | 'integration' | 'e2e'
  testFramework: 'bun' | 'jest' | 'vitest'
  mockingNeeds: Array<{
    dependency: string
    type: 'full' | 'partial' | 'spy'
  }>
  edgeCases: string[]
  businessRules: string[]
}

export interface TestGenerationResult {
  testFile: string
  testContent: string
  coverage: {
    expectedLines: number
    expectedFunctions: number
    expectedBranches: number
  }
  dependencies: string[]
  setupRequirements: string[]
  runInstructions: string[]
}

export class TestWorkflowManager {
  private aiProvider: AIProvider
  private queryEngine: IntelligentQueryEngine
  private workflowState: WorkflowStateMachine
  private coverageAnalyzer: TestCoverageAnalyzer
  private strategyEngine: TestStrategyDecisionEngine
  private projectRoot: string

  constructor(aiProvider?: AIProvider) {
    // Use provided AI provider or create default one
    this.aiProvider = aiProvider || createDefaultAIProvider()
    this.queryEngine = new IntelligentQueryEngine()
    this.workflowState = new WorkflowStateMachine('TEST_WORKFLOW')
    this.coverageAnalyzer = new TestCoverageAnalyzer()
    this.strategyEngine = new TestStrategyDecisionEngine(this.aiProvider)
    this.projectRoot = process.cwd()

    logger.info('TestWorkflowManager initialized', {
      aiProvider: this.aiProvider.getName(),
      projectRoot: this.projectRoot
    })
  }

  /**
   * Intelligent test timing control - analyzes when to generate tests
   */
  async analyzeTestTiming(context: TestWorkflowContext): Promise<{
    timingStrategy: TaskComplexityAnalysis
    coverageAnalysis: CoverageAnalysisResult
    recommendation: 'generate_now' | 'generate_later' | 'incremental' | 'skip'
    reasoning: string
  }> {
    logger.info('Analyzing intelligent test timing control', { 
      taskDescription: context.taskDescription,
      testType: context.testType 
    })

    try {
      // 1. Analyze task complexity for timing decision
      const timingStrategy = await this.coverageAnalyzer.analyzeTestTiming(
        context.taskDescription,
        {
          files: context.targetFiles,
          dependencies: await this.extractDependenciesFromFiles(context.targetFiles || [])
        }
      )

      // 2. Get current coverage analysis
      const coverageAnalysis = await this.coverageAnalyzer.analyzeCoverage({
        includeFiles: context.targetFiles,
        generateReport: false
      })

      // 3. Make intelligent timing decision
      const decision = this.makeTimingDecision(timingStrategy, coverageAnalysis, context)

      logger.info('Test timing analysis completed', {
        complexity: timingStrategy.score,
        strategy: timingStrategy.recommendation.mode,
        generateAt: timingStrategy.recommendation.generateAt,
        decision: decision.recommendation
      })

      return decision
    } catch (error) {
      logger.error('Test timing analysis failed', error instanceof Error ? error : new Error(String(error)))
      
      // Fallback to traditional approach
      return {
        timingStrategy: {
          score: 5,
          factors: [{ factor: 'Fallback analysis', weight: 1, contribution: 5 }],
          recommendation: {
            mode: 'traditional',
            generateAt: 'completion',
            testTypes: ['unit'],
            priority: 'future',
            reasoning: 'Fallback to traditional testing due to analysis failure'
          }
        },
        coverageAnalysis: await this.createFallbackCoverageAnalysis(),
        recommendation: 'generate_later',
        reasoning: 'Analysis failed, defaulting to safe traditional approach'
      }
    }
  }

  /**
   * Enhanced AI-driven test strategy analysis 
   * Integrates timing control with multi-factor strategy decision engine
   */
  async analyzeTestStrategy(context: TestWorkflowContext): Promise<{
    strategyDecision: TestStrategyDecision
    timingAnalysis: {
      strategy: TaskComplexityAnalysis
      recommendation: string
    }
    integration: {
      selectedStrategy: string
      confidence: number
      reasoning: string[]
    }
  }> {
    logger.info('Analyzing comprehensive test strategy', {
      taskDescription: context.taskDescription,
      hasStrategyFactors: !!context.strategyFactors,
      hasAnalysisContext: !!context.analysisContext
    })

    try {
      // 1. Analyze timing if not already done
      const timingAnalysis = await this.analyzeTestTiming(context)

      // 2. Prepare strategy factors (use provided or infer from context)
      const strategyFactors = context.strategyFactors || this.inferStrategyFactors(context, timingAnalysis)

      // 3. Prepare analysis context (use provided or infer from project)
      const analysisContext = context.analysisContext || await this.inferAnalysisContext(context)

      // 4. Run strategy decision engine
      const strategyDecision = await this.strategyEngine.analyzeTestStrategy(
        strategyFactors,
        analysisContext,
        context.targetFiles
      )

      // 5. Create integrated recommendation
      const integration = this.integrateTimingAndStrategy(
        timingAnalysis,
        strategyDecision,
        context
      )

      logger.info('Test strategy analysis completed', {
        strategy: strategyDecision.primaryStrategy,
        confidence: strategyDecision.confidence,
        timingRecommendation: timingAnalysis.recommendation
      })

      return {
        strategyDecision,
        timingAnalysis: {
          strategy: timingAnalysis.timingStrategy,
          recommendation: timingAnalysis.recommendation
        },
        integration
      }
    } catch (error) {
      logger.error('Test strategy analysis failed', error instanceof Error ? error : new Error(String(error)))
      
      // Fallback analysis
      return this.createFallbackStrategyAnalysis(context)
    }
  }

  /**
   * æ‰§è¡Œæµ‹è¯•å·¥ä½œæµåˆ†æ (Legacy method - now enhanced with strategy engine)
   */
  async executeTestWorkflow(context: TestWorkflowContext): Promise<{
    analysis: TestAnalysisResult
    recommendations: any
    nextActions: string[]
    timingControl?: {
      strategy: TaskComplexityAnalysis
      recommendation: string
    }
  }> {
    logger.info('å¯åŠ¨æµ‹è¯• AI å·¥ä½œæµ', { 
      taskDescription: context.taskDescription,
      testType: context.testType 
    })

    try {
      // 0. **NEW** Intelligent test timing control analysis
      const timingControl = await this.analyzeTestTiming(context)
      
      // 1. é¡¹ç›®çŠ¶æ€åˆ†æ
      const projectStatus = await this.analyzeProjectTestStatus()
      
      // 2. Graph RAG æŸ¥è¯¢ç°æœ‰æµ‹è¯•å®ç°
      const existingTestContext = await this.queryExistingTests(context)
      
      // 3. è¦†ç›–ç‡åˆ†æ (enhanced with timing control)
      const coverageAnalysis = timingControl.coverageAnalysis
      
      // 4. AI æ™ºèƒ½æ¨è (enhanced with timing awareness)
      const aiRecommendations = await this.generateAIRecommendations(
        context, 
        projectStatus,
        existingTestContext,
        { coverage: this.adaptCoverageForLegacy(coverageAnalysis), gaps: [] },
        timingControl.timingStrategy
      )
      
      // 5. ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ (timing-aware)
      const executionPlan = await this.createTestExecutionPlan(
        context,
        aiRecommendations,
        timingControl.recommendation
      )

      const analysis: TestAnalysisResult = {
        currentCoverage: this.adaptCoverageForLegacy(coverageAnalysis),
        testGaps: this.extractGapsFromAnalysis(coverageAnalysis),
        existingTests: existingTestContext.tests,
        recommendations: aiRecommendations
      }

      return {
        analysis,
        recommendations: aiRecommendations,
        nextActions: executionPlan.steps,
        timingControl: {
          strategy: timingControl.timingStrategy,
          recommendation: timingControl.recommendation
        }
      }
    } catch (error) {
      logger.error('æµ‹è¯•å·¥ä½œæµæ‰§è¡Œå¤±è´¥', { error: error.message })
      throw error
    }
  }

  /**
   * AI é©±åŠ¨çš„æµ‹è¯•ç”Ÿæˆ
   */
  async generateTests(request: TestGenerationRequest): Promise<TestGenerationResult> {
    logger.info('å¼€å§‹ AI æµ‹è¯•ç”Ÿæˆ', { sourceFile: request.sourceFile })

    try {
      // 1. åˆ†ææºä»£ç 
      const sourceAnalysis = await this.analyzeSourceCode(request.sourceFile)
      
      // 2. Graph RAG æŸ¥è¯¢ç›¸ä¼¼æµ‹è¯•æ¨¡å¼
      const testPatterns = await this.queryTestPatterns(request.sourceFile)
      
      // 3. æ„å»ºæµ‹è¯•ç”Ÿæˆ Prompt
      const prompt = await this.buildTestGenerationPrompt(
        request, 
        sourceAnalysis, 
        testPatterns
      )
      
      // 4. AI ç”Ÿæˆæµ‹è¯•ä»£ç 
      const aiResponse = await this.aiProvider.generateResponse({
        prompt,
        temperature: 0.3, // é™ä½éšæœºæ€§ï¼Œç¡®ä¿ä»£ç è´¨é‡
        schema: {
          type: 'object',
          properties: {
            testContent: { type: 'string' },
            imports: { type: 'array', items: { type: 'string' } },
            testCases: { 
              type: 'array', 
              items: {
                type: 'object',
                properties: {
                  name: { type: 'string' },
                  description: { type: 'string' },
                  type: { type: 'string', enum: ['unit', 'integration', 'edge-case'] }
                }
              }
            },
            mockingSetup: { type: 'array', items: { type: 'string' } },
            coverage: {
              type: 'object',
              properties: {
                expectedLines: { type: 'number' },
                expectedFunctions: { type: 'number' },
                expectedBranches: { type: 'number' }
              }
            }
          },
          required: ['testContent', 'testCases', 'coverage']
        }
      })

      // 5. éªŒè¯å’Œä¼˜åŒ–ç”Ÿæˆçš„æµ‹è¯•
      const optimizedTest = await this.optimizeGeneratedTest(
        aiResponse.data,
        request
      )

      return {
        testFile: this.getTestFilePath(request.sourceFile),
        testContent: optimizedTest.testContent,
        coverage: optimizedTest.coverage,
        dependencies: optimizedTest.dependencies,
        setupRequirements: optimizedTest.setupRequirements,
        runInstructions: optimizedTest.runInstructions
      }
    } catch (error) {
      logger.error('AI æµ‹è¯•ç”Ÿæˆå¤±è´¥', { 
        sourceFile: request.sourceFile,
        error: error.message 
      })
      throw error
    }
  }

  /**
   * æ™ºèƒ½æµ‹è¯•ä¼˜åŒ–å»ºè®®
   */
  async optimizeExistingTests(testFiles: string[]): Promise<{
    optimizations: Array<{
      file: string
      issues: string[]
      suggestions: string[]
      priority: 'high' | 'medium' | 'low'
    }>
    overallScore: number
  }> {
    logger.info('å¼€å§‹æµ‹è¯•ä¼˜åŒ–åˆ†æ', { fileCount: testFiles.length })

    const optimizations = []

    for (const testFile of testFiles) {
      try {
        // 1. åˆ†ææµ‹è¯•æ–‡ä»¶è´¨é‡
        const testAnalysis = await this.analyzeTestQuality(testFile)
        
        // 2. AI è¯„ä¼°å’Œå»ºè®®
        const aiOptimization = await this.getAIOptimizationSuggestions(
          testFile,
          testAnalysis
        )

        optimizations.push({
          file: testFile,
          issues: testAnalysis.issues,
          suggestions: aiOptimization.suggestions,
          priority: aiOptimization.priority
        })
      } catch (error) {
        logger.warn('æµ‹è¯•æ–‡ä»¶åˆ†æå¤±è´¥', { 
          testFile,
          error: error.message 
        })
      }
    }

    // è®¡ç®—æ•´ä½“æµ‹è¯•è´¨é‡è¯„åˆ†
    const overallScore = this.calculateTestQualityScore(optimizations)

    return {
      optimizations,
      overallScore
    }
  }

  /**
   * æ‰§è¡Œæ™ºèƒ½æµ‹è¯•è¿è¡Œ
   */
  async runIntelligentTests(options: {
    testType?: 'unit' | 'integration' | 'e2e' | 'all'
    coverage?: boolean
    watch?: boolean
    aiAnalysis?: boolean
  } = {}): Promise<{
    results: any
    analysis: any
    recommendations: string[]
  }> {
    logger.info('å¼€å§‹æ™ºèƒ½æµ‹è¯•è¿è¡Œ', options)

    try {
      // 1. è¿è¡Œæµ‹è¯•
      const testResults = await this.executeTests(options)
      
      // 2. AI åˆ†ææµ‹è¯•ç»“æœ
      let analysis = null
      if (options.aiAnalysis) {
        analysis = await this.analyzeTestResults(testResults)
      }

      // 3. ç”Ÿæˆæ”¹è¿›å»ºè®®
      const recommendations = await this.generateTestRecommendations(
        testResults,
        analysis
      )

      return {
        results: testResults,
        analysis,
        recommendations
      }
    } catch (error) {
      logger.error('æ™ºèƒ½æµ‹è¯•è¿è¡Œå¤±è´¥', { error: error.message })
      throw error
    }
  }

  // ========== ç§æœ‰æ–¹æ³• ==========

  private async analyzeProjectTestStatus() {
    logger.debug('åˆ†æé¡¹ç›®æµ‹è¯•çŠ¶æ€')
    
    try {
      // 1. æ£€æŸ¥æµ‹è¯•é…ç½®
      const bunConfig = existsSync(join(this.projectRoot, 'bunfig.toml'))
      const jestConfig = existsSync(join(this.projectRoot, 'jest.config.js'))
      const vitestConfig = existsSync(join(this.projectRoot, 'vitest.config.ts'))

      // 2. ç»Ÿè®¡æµ‹è¯•æ–‡ä»¶
      const { stdout: testFiles } = await execAsync('find . -name "*.test.*" -o -name "*.spec.*" | wc -l')
      const testFileCount = parseInt(testFiles.trim())

      // 3. è·å–æœ€è¿‘çš„æµ‹è¯•è¿è¡Œç»“æœ
      let lastTestRun = null
      try {
        if (existsSync(join(this.projectRoot, 'coverage', 'test-report.json'))) {
          const reportContent = readFileSync(join(this.projectRoot, 'coverage', 'test-report.json'), 'utf-8')
          lastTestRun = JSON.parse(reportContent)
        }
      } catch {}

      return {
        testFramework: bunConfig ? 'bun' : jestConfig ? 'jest' : vitestConfig ? 'vitest' : 'unknown',
        testFileCount,
        lastTestRun,
        hasCI: existsSync(join(this.projectRoot, '.github', 'workflows'))
      }
    } catch (error) {
      logger.warn('é¡¹ç›®æµ‹è¯•çŠ¶æ€åˆ†æå¤±è´¥', { error: error.message })
      return {
        testFramework: 'unknown',
        testFileCount: 0,
        lastTestRun: null,
        hasCI: false
      }
    }
  }

  private async queryExistingTests(context: TestWorkflowContext) {
    logger.debug('æŸ¥è¯¢ç°æœ‰æµ‹è¯•å®ç°')
    
    try {
      // ä½¿ç”¨ Graph RAG æŸ¥è¯¢ç›¸å…³æµ‹è¯•
      const query = `test ${context.taskDescription} ${context.testType}`
      const results = await this.queryEngine.searchRelated(query, {
        includeTests: true,
        maxResults: 10
      })

      return {
        tests: results.relatedItems?.filter(item => 
          item.type === 'test' || item.file?.includes('.test.') || item.file?.includes('.spec.')
        ) || [],
        patterns: results.patterns || [],
        suggestions: results.suggestions || []
      }
    } catch (error) {
      logger.warn('Graph RAG æµ‹è¯•æŸ¥è¯¢å¤±è´¥', { error: error.message })
      return { tests: [], patterns: [], suggestions: [] }
    }
  }

  private async analyzeCoverageGaps(context: TestWorkflowContext) {
    logger.debug('åˆ†ææµ‹è¯•è¦†ç›–ç‡ç¼ºå£')

    try {
      // 1. è¿è¡Œè¦†ç›–ç‡åˆ†æ
      const { stdout } = await execAsync('bun test --coverage --reporter=json', { 
        cwd: this.projectRoot 
      })
      const coverageData = JSON.parse(stdout)

      // 2. åˆ†æè¦†ç›–ç‡ç¼ºå£
      const gaps = []
      for (const [file, data] of Object.entries(coverageData.files || {})) {
        const fileData = data as any
        if (fileData.lines?.percentage < (context.coverageThreshold?.lines || 80)) {
          gaps.push({
            file: relative(this.projectRoot, file),
            uncoveredLines: this.extractUncoveredLines(fileData),
            missingFunctions: this.extractMissingFunctions(fileData),
            suggestedTests: [] // å°†ç”± AI å¡«å……
          })
        }
      }

      return {
        coverage: coverageData.summary || { lines: 0, functions: 0, branches: 0, statements: 0 },
        gaps
      }
    } catch (error) {
      logger.warn('è¦†ç›–ç‡åˆ†æå¤±è´¥', { error: error.message })
      return {
        coverage: { lines: 0, functions: 0, branches: 0, statements: 0 },
        gaps: []
      }
    }
  }

  private extractUncoveredLines(fileData: any): number[] {
    if (!fileData.l) return []
    
    return Object.entries(fileData.l)
      .filter(([line, count]) => (count as number) === 0)
      .map(([line]) => parseInt(line))
  }

  private extractMissingFunctions(fileData: any): string[] {
    if (!fileData.f) return []
    
    return Object.entries(fileData.f)
      .filter(([func, count]) => (count as number) === 0)
      .map(([func]) => func)
  }

  private async generateAIRecommendations(
    context: TestWorkflowContext,
    projectStatus: any,
    testContext: any,
    coverageAnalysis: any,
    timingStrategy?: TaskComplexityAnalysis
  ) {
    logger.debug('ç”Ÿæˆ AI æµ‹è¯•æ¨è')

    try {
      const prompt = `
ä½œä¸ºæµ‹è¯•æ¶æ„ä¸“å®¶ï¼ŒåŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆæµ‹è¯•ç­–ç•¥å»ºè®®ï¼š

## ä»»åŠ¡æè¿°
${context.taskDescription}

## æµ‹è¯•ç±»å‹
${context.testType}

## é¡¹ç›®çŠ¶æ€
- æµ‹è¯•æ¡†æ¶: ${projectStatus.testFramework}
- ç°æœ‰æµ‹è¯•æ–‡ä»¶: ${projectStatus.testFileCount}
- CIé›†æˆ: ${projectStatus.hasCI ? 'å·²é…ç½®' : 'æœªé…ç½®'}

## è¦†ç›–ç‡çŠ¶æ€
- å½“å‰è¡Œè¦†ç›–ç‡: ${coverageAnalysis.coverage.lines}%
- å‘ç° ${coverageAnalysis.gaps.length} ä¸ªè¦†ç›–ç‡ç¼ºå£

## ç°æœ‰ç›¸å…³æµ‹è¯•
${testContext.tests.length > 0 ? 
  testContext.tests.map((t: any) => `- ${t.file}: ${t.description || 'æ— æè¿°'}`).join('\n') : 
  'æœªæ‰¾åˆ°ç›¸å…³æµ‹è¯•'
}

è¯·æä¾›ï¼š
1. æµ‹è¯•ç­–ç•¥å»ºè®® (TDD/BDD/å…¶ä»–)
2. ä¼˜å…ˆçº§æ’åºçš„è¡ŒåŠ¨é¡¹
3. é¢„ä¼°å·¥ä½œé‡ (å°æ—¶)
4. é£é™©è¯„ä¼°å’Œç¼“è§£ç­–ç•¥
`

      const response = await this.aiProvider.generateResponse({
        prompt,
        temperature: 0.4,
        schema: {
          type: 'object',
          properties: {
            strategy: { type: 'string' },
            priority: { type: 'string', enum: ['high', 'medium', 'low'] },
            actions: {
              type: 'array',
              items: {
                type: 'object',
                properties: {
                  type: { type: 'string' },
                  target: { type: 'string' },
                  description: { type: 'string' },
                  effort: { type: 'string', enum: ['low', 'medium', 'high'] },
                  priority: { type: 'string', enum: ['high', 'medium', 'low'] }
                }
              }
            },
            estimatedHours: { type: 'number' },
            risks: { type: 'array', items: { type: 'string' } }
          }
        }
      })

      return response.data
    } catch (error) {
      logger.warn('AI æ¨èç”Ÿæˆå¤±è´¥', { error: error.message })
      return {
        strategy: 'balanced',
        priority: 'medium',
        actions: [],
        estimatedHours: 0,
        risks: []
      }
    }
  }

  private async createTestExecutionPlan(
    context: TestWorkflowContext, 
    recommendations: any,
    timingRecommendation?: string
  ) {
    const baseSteps = [
      `åˆ†æ ${context.testType} æµ‹è¯•éœ€æ±‚`,
      `åŸºäº ${recommendations.strategy} ç­–ç•¥å¼€å§‹å®æ–½`
    ]

    // Add timing-aware steps
    if (timingRecommendation === 'generate_now') {
      baseSteps.unshift('ğŸš€ ç«‹å³ç”Ÿæˆæµ‹è¯•æ¡†æ¶ (TDDæ¨¡å¼)')
    } else if (timingRecommendation === 'incremental') {
      baseSteps.push('ğŸ“ å¢é‡å¼æµ‹è¯•å¼€å‘')
    } else if (timingRecommendation === 'generate_later') {
      baseSteps.push('â° ç¼–ç å®Œæˆåç”Ÿæˆæµ‹è¯•')
    }

    return {
      steps: [
        ...baseSteps,
        ...recommendations.actions.map((action: any) => 
          `${action.type}: ${action.description} (${action.effort} effort)`
        ),
        'æ‰§è¡Œæµ‹è¯•éªŒè¯',
        'ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š'
      ]
    }
  }

  private async analyzeSourceCode(sourceFile: string) {
    // ç®€åŒ–çš„æºä»£ç åˆ†æ
    try {
      const content = readFileSync(sourceFile, 'utf-8')
      
      // æå–å‡½æ•°ã€ç±»ã€å¯¼å‡ºç­‰
      const functions = (content.match(/function\s+\w+|const\s+\w+\s*=|export\s+(function|const|class)/g) || [])
      const imports = (content.match(/import.*from/g) || [])
      const exports = (content.match(/export/g) || [])

      return {
        functions: functions.length,
        imports: imports.length,
        exports: exports.length,
        complexity: this.calculateComplexity(content),
        dependencies: this.extractDependencies(imports)
      }
    } catch (error) {
      logger.warn('æºä»£ç åˆ†æå¤±è´¥', { sourceFile, error: error.message })
      return {
        functions: 0,
        imports: 0,
        exports: 0,
        complexity: 1,
        dependencies: []
      }
    }
  }

  private calculateComplexity(content: string): number {
    // ç®€åŒ–çš„å¾ªç¯å¤æ‚åº¦è®¡ç®—
    const conditions = (content.match(/if\s*\(|while\s*\(|for\s*\(|switch\s*\(|\|\||&&/g) || []).length
    return Math.max(1, conditions)
  }

  private extractDependencies(imports: string[]): string[] {
    return imports
      .map(imp => {
        const match = imp.match(/from\s+['"]([^'"]+)['"]/)
        return match ? match[1] : null
      })
      .filter(Boolean) as string[]
  }

  private async queryTestPatterns(sourceFile: string) {
    // æŸ¥è¯¢ç›¸ä¼¼çš„æµ‹è¯•æ¨¡å¼
    try {
      const query = `test patterns for ${sourceFile}`
      const results = await this.queryEngine.searchRelated(query, {
        includeTests: true,
        maxResults: 5
      })
      return results.patterns || []
    } catch (error) {
      logger.warn('æµ‹è¯•æ¨¡å¼æŸ¥è¯¢å¤±è´¥', { error: error.message })
      return []
    }
  }

  private async buildTestGenerationPrompt(
    request: TestGenerationRequest,
    sourceAnalysis: any,
    testPatterns: any[]
  ) {
    return `
ä½œä¸ºèµ„æ·±æµ‹è¯•å·¥ç¨‹å¸ˆï¼Œä¸ºä»¥ä¸‹æºä»£ç ç”Ÿæˆé«˜è´¨é‡çš„ ${request.testType} æµ‹è¯•ï¼š

## æºæ–‡ä»¶ä¿¡æ¯
- æ–‡ä»¶: ${request.sourceFile}
- å‡½æ•°æ•°é‡: ${sourceAnalysis.functions}
- å¤æ‚åº¦: ${sourceAnalysis.complexity}
- ä¾èµ–é¡¹: ${sourceAnalysis.dependencies.join(', ')}

## æµ‹è¯•è¦æ±‚
- æ¡†æ¶: ${request.testFramework}
- ç±»å‹: ${request.testType}
- Mock éœ€æ±‚: ${request.mockingNeeds.map(m => m.dependency).join(', ')}

## ä¸šåŠ¡è§„åˆ™
${request.businessRules.join('\n')}

## è¾¹ç•Œæƒ…å†µ
${request.edgeCases.join('\n')}

## å‚è€ƒæ¨¡å¼
${testPatterns.length > 0 ? testPatterns.map(p => `- ${p}`).join('\n') : 'æ— '}

è¯·ç”Ÿæˆï¼š
1. å®Œæ•´çš„æµ‹è¯•æ–‡ä»¶å†…å®¹
2. å¿…è¦çš„å¯¼å…¥è¯­å¥
3. è¯¦ç»†çš„æµ‹è¯•ç”¨ä¾‹
4. Mock è®¾ç½®ä»£ç 
5. é¢„æœŸè¦†ç›–ç‡æŒ‡æ ‡
`
  }

  private async optimizeGeneratedTest(aiResponse: any, request: TestGenerationRequest) {
    // ä¼˜åŒ–ç”Ÿæˆçš„æµ‹è¯•ä»£ç 
    return {
      testContent: aiResponse.testContent,
      coverage: aiResponse.coverage,
      dependencies: this.extractTestDependencies(aiResponse.testContent),
      setupRequirements: aiResponse.mockingSetup || [],
      runInstructions: [
        `bun test ${this.getTestFilePath(request.sourceFile)}`,
        `bun test --coverage ${this.getTestFilePath(request.sourceFile)}`
      ]
    }
  }

  private extractTestDependencies(testContent: string): string[] {
    const imports = testContent.match(/import.*from\s+['"]([^'"]+)['"]/g) || []
    return imports.map(imp => {
      const match = imp.match(/from\s+['"]([^'"]+)['"]/)
      return match ? match[1] : null
    }).filter(Boolean) as string[]
  }

  private getTestFilePath(sourceFile: string): string {
    const dir = sourceFile.replace(/\/[^/]+$/, '')
    const name = sourceFile.replace(/^.*\//, '').replace(/\.(ts|js)$/, '')
    return join(dir, '__tests__', `${name}.test.ts`)
  }

  private async analyzeTestQuality(testFile: string) {
    // åˆ†ææµ‹è¯•æ–‡ä»¶è´¨é‡
    try {
      const content = readFileSync(testFile, 'utf-8')
      const issues = []
      
      // æ£€æŸ¥å¸¸è§é—®é¢˜
      if (!content.includes('describe') && !content.includes('test')) {
        issues.push('ç¼ºå°‘æµ‹è¯•ç»“æ„')
      }
      
      if (!content.includes('expect')) {
        issues.push('ç¼ºå°‘æ–­è¨€')
      }

      const testCount = (content.match(/test\s*\(|it\s*\(/g) || []).length

      return {
        testCount,
        issues,
        hasSetup: content.includes('beforeEach') || content.includes('beforeAll'),
        hasTeardown: content.includes('afterEach') || content.includes('afterAll'),
        complexity: this.calculateComplexity(content)
      }
    } catch (error) {
      logger.warn('æµ‹è¯•è´¨é‡åˆ†æå¤±è´¥', { testFile, error: error.message })
      return {
        testCount: 0,
        issues: ['æ–‡ä»¶è¯»å–å¤±è´¥'],
        hasSetup: false,
        hasTeardown: false,
        complexity: 0
      }
    }
  }

  private async getAIOptimizationSuggestions(testFile: string, analysis: any) {
    // AI ä¼˜åŒ–å»ºè®®
    const severity = analysis.issues.length > 3 ? 'high' : analysis.issues.length > 1 ? 'medium' : 'low'
    
    return {
      suggestions: analysis.issues.map((issue: string) => `ä¿®å¤: ${issue}`),
      priority: severity as 'high' | 'medium' | 'low'
    }
  }

  private calculateTestQualityScore(optimizations: any[]): number {
    if (optimizations.length === 0) return 100

    const highIssues = optimizations.filter(opt => opt.priority === 'high').length
    const mediumIssues = optimizations.filter(opt => opt.priority === 'medium').length
    const lowIssues = optimizations.filter(opt => opt.priority === 'low').length

    // ç®€åŒ–çš„è¯„åˆ†ç®—æ³•
    const score = Math.max(0, 100 - (highIssues * 20) - (mediumIssues * 10) - (lowIssues * 5))
    return score
  }

  private async executeTests(options: any) {
    // æ‰§è¡Œæµ‹è¯•
    try {
      const testCommand = this.buildTestCommand(options)
      const { stdout, stderr } = await execAsync(testCommand, { cwd: this.projectRoot })
      
      return {
        success: true,
        output: stdout,
        errors: stderr,
        command: testCommand
      }
    } catch (error) {
      return {
        success: false,
        output: '',
        errors: error.message,
        command: 'test execution failed'
      }
    }
  }

  private buildTestCommand(options: any): string {
    let cmd = 'bun test'
    
    if (options.testType && options.testType !== 'all') {
      cmd += ` --testNamePattern=${options.testType}`
    }
    
    if (options.coverage) {
      cmd += ' --coverage'
    }
    
    if (options.watch) {
      cmd += ' --watch'
    }
    
    return cmd
  }

  private async analyzeTestResults(results: any) {
    // AI åˆ†ææµ‹è¯•ç»“æœ
    if (!results.success) {
      return {
        status: 'failed',
        issues: [results.errors],
        suggestions: ['ä¿®å¤æµ‹è¯•é”™è¯¯', 'æ£€æŸ¥æµ‹è¯•é…ç½®']
      }
    }

    return {
      status: 'passed',
      issues: [],
      suggestions: ['ç»§ç»­ä¿æŒè‰¯å¥½çš„æµ‹è¯•è¦†ç›–ç‡']
    }
  }

  private async generateTestRecommendations(results: any, analysis: any): Promise<string[]> {
    const recommendations = []
    
    if (!results.success) {
      recommendations.push('ä¿®å¤å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹')
      recommendations.push('æ£€æŸ¥æµ‹è¯•ä¾èµ–å’Œé…ç½®')
    } else {
      recommendations.push('è€ƒè™‘å¢åŠ è¾¹ç•Œæƒ…å†µæµ‹è¯•')
      recommendations.push('ä¼˜åŒ–æµ‹è¯•æ€§èƒ½')
    }

    if (analysis?.suggestions) {
      recommendations.push(...analysis.suggestions)
    }

    return recommendations
  }

  // ========== NEW: Test Strategy Engine Integration Methods ==========

  /**
   * Infer strategy factors from timing analysis and context
   */
  private inferStrategyFactors(
    context: TestWorkflowContext, 
    timingAnalysis: any
  ): TestStrategyFactors {
    const { timingStrategy } = timingAnalysis
    
    return {
      complexity: timingStrategy.score || 5,
      businessImpact: context.testType === 'e2e' ? 8 : 6,
      riskLevel: timingStrategy.score >= 7 ? 8 : 5,
      currentCoverage: timingAnalysis.coverageAnalysis?.overall?.lines?.percentage || 0,
      changeFrequency: context.targetFiles?.length > 5 ? 7 : 4,
      teamExperience: 6 // Default mid-level, could be configurable
    }
  }

  /**
   * Infer analysis context from project structure
   */
  private async inferAnalysisContext(context: TestWorkflowContext): Promise<StrategyAnalysisContext> {
    // Try to detect project type from package.json or file structure
    let projectType: StrategyAnalysisContext['projectType'] = 'web-app'
    let framework = 'unknown'
    
    try {
      const packageJsonPath = join(this.projectRoot, 'package.json')
      if (existsSync(packageJsonPath)) {
        const packageJson = JSON.parse(readFileSync(packageJsonPath, 'utf-8'))
        
        // Detect framework
        if (packageJson.dependencies?.['next'] || packageJson.devDependencies?.['next']) {
          framework = 'next.js'
          projectType = 'web-app'
        } else if (packageJson.dependencies?.['express'] || packageJson.dependencies?.['fastify']) {
          projectType = 'api'
          framework = 'node.js'
        } else if (packageJson.name?.includes('lib') || packageJson.main) {
          projectType = 'library'
        }
      }
      
      // Determine project size based on file count
      const { stdout } = await execAsync('find . -name "*.ts" -o -name "*.js" | grep -v node_modules | wc -l')
      const fileCount = parseInt(stdout.trim())
      const size = fileCount < 50 ? 'small' : fileCount < 200 ? 'medium' : fileCount < 1000 ? 'large' : 'enterprise'

      return {
        projectType,
        codebase: {
          language: 'typescript', // Assume TypeScript for LinchKit
          framework,
          size: size as any
        },
        team: {
          size: 3, // Default assumption
          experience: 'mid',
          testingCulture: 'medium'
        },
        timeline: {
          isUrgent: false,
          hasDeadline: true,
          iterationLength: 2
        }
      }
    } catch (error) {
      logger.warn('Could not infer project context, using defaults', error)
      return {
        projectType: 'web-app',
        codebase: { language: 'typescript', framework: 'unknown', size: 'medium' },
        team: { size: 3, experience: 'mid', testingCulture: 'medium' },
        timeline: { isUrgent: false, hasDeadline: true, iterationLength: 2 }
      }
    }
  }

  /**
   * Integrate timing and strategy recommendations
   */
  private integrateTimingAndStrategy(
    timingAnalysis: any,
    strategyDecision: TestStrategyDecision,
    context: TestWorkflowContext
  ): { selectedStrategy: string; confidence: number; reasoning: string[] } {
    const { recommendation: timingRec } = timingAnalysis
    const { primaryStrategy, confidence, reasoning } = strategyDecision

    // Combine recommendations
    let selectedStrategy = primaryStrategy
    let integratedConfidence = confidence
    const integratedReasoning = [...reasoning]

    // Adjust strategy based on timing analysis
    if (timingRec === 'generate_now' && primaryStrategy === 'traditional') {
      selectedStrategy = 'tdd'
      integratedReasoning.push('Upgraded to TDD based on immediate test generation timing')
      integratedConfidence = Math.min(confidence + 0.1, 0.95)
    } else if (timingRec === 'skip' && confidence < 0.7) {
      selectedStrategy = 'traditional'
      integratedReasoning.push('Simplified to traditional approach due to low confidence and skip recommendation')
      integratedConfidence = 0.8
    }

    // Add timing-specific reasoning
    integratedReasoning.push(`Timing analysis recommends: ${timingRec}`)
    if (timingAnalysis.timingStrategy.recommendation.mode) {
      integratedReasoning.push(`Development mode: ${timingAnalysis.timingStrategy.recommendation.mode}`)
    }

    return {
      selectedStrategy,
      confidence: integratedConfidence,
      reasoning: integratedReasoning.slice(0, 6) // Limit reasoning length
    }
  }

  /**
   * Create fallback strategy analysis when main analysis fails
   */
  private createFallbackStrategyAnalysis(context: TestWorkflowContext): any {
    return {
      strategyDecision: {
        primaryStrategy: 'traditional',
        secondaryStrategies: [],
        confidence: 0.6,
        reasoning: ['Fallback analysis due to strategy engine failure'],
        resourceAllocation: { unitTests: 70, integrationTests: 20, e2eTests: 8, performanceTests: 2 },
        prioritization: [],
        estimatedEffort: { hours: 8, complexity: 'moderate' }
      },
      timingAnalysis: {
        strategy: { score: 5, recommendation: { mode: 'traditional', generateAt: 'completion' } },
        recommendation: 'generate_later'
      },
      integration: {
        selectedStrategy: 'traditional',
        confidence: 0.6,
        reasoning: ['Conservative fallback approach', 'Manual refinement recommended']
      }
    }
  }

  // ========== Enhanced AI Provider Methods ==========

  /**
   * Update AI provider with error handling and fallback
   */
  updateAIProvider(provider: AIProvider): void {
    this.aiProvider = provider
    this.strategyEngine = new TestStrategyDecisionEngine(provider)
    logger.info('Updated AI provider', { provider: provider.getName() })
  }

  /**
   * Get AI provider info and availability
   */
  async getProviderStatus(): Promise<{
    name: string
    id: string
    available: boolean
    error?: string
  }> {
    try {
      const available = await this.aiProvider.isAvailable()
      return {
        name: this.aiProvider.getName(),
        id: this.aiProvider.getId(),
        available
      }
    } catch (error) {
      return {
        name: this.aiProvider.getName(),
        id: this.aiProvider.getId(), 
        available: false,
        error: error instanceof Error ? error.message : 'Unknown error'
      }
    }
  }

  // ========== Legacy: Intelligent Test Timing Control Support Methods ==========

  /**
   * Make intelligent timing decision based on analysis
   */
  private makeTimingDecision(
    timingStrategy: TaskComplexityAnalysis,
    coverageAnalysis: CoverageAnalysisResult,
    context: TestWorkflowContext
  ): {
    timingStrategy: TaskComplexityAnalysis
    coverageAnalysis: CoverageAnalysisResult
    recommendation: 'generate_now' | 'generate_later' | 'incremental' | 'skip'
    reasoning: string
  } {
    const { score, recommendation } = timingStrategy
    const { overall } = coverageAnalysis
    
    let decision: 'generate_now' | 'generate_later' | 'incremental' | 'skip'
    let reasoning: string

    // High complexity or critical business logic
    if (score >= 8 || recommendation.mode === 'tdd') {
      decision = 'generate_now'
      reasoning = `High complexity (${score}/10) requires TDD approach. ${recommendation.reasoning}`
    }
    // Medium complexity with existing low coverage
    else if (score >= 6 && overall.lines.percentage < 70) {
      decision = 'incremental' 
      reasoning = `Medium complexity with low coverage (${overall.lines.percentage}%). Incremental testing recommended.`
    }
    // Low complexity but critical gaps
    else if (coverageAnalysis.gapAnalysis.criticalGaps > 0) {
      decision = 'generate_later'
      reasoning = `${coverageAnalysis.gapAnalysis.criticalGaps} critical coverage gaps found. Generate tests after implementation.`
    }
    // Very low complexity with good coverage
    else if (score < 4 && overall.lines.percentage > 80) {
      decision = 'skip'
      reasoning = `Low complexity (${score}/10) with good coverage (${overall.lines.percentage}%). Testing may be optional.`
    }
    // Default case
    else {
      decision = recommendation.generateAt === 'planning' ? 'generate_now' : 'generate_later'
      reasoning = `Following ${recommendation.mode} strategy: ${recommendation.reasoning}`
    }

    return {
      timingStrategy,
      coverageAnalysis,
      recommendation: decision,
      reasoning
    }
  }

  /**
   * Extract dependencies from target files for timing analysis
   */
  private async extractDependenciesFromFiles(targetFiles: string[]): Promise<string[]> {
    const dependencies: Set<string> = new Set()

    for (const file of targetFiles) {
      try {
        const content = readFileSync(file, 'utf-8')
        const importMatches = content.match(/import.*from\s+['"]([^'"]+)['"]/g) || []
        
        importMatches.forEach(match => {
          const depMatch = match.match(/from\s+['"]([^'"]+)['"]/)
          if (depMatch && !depMatch[1].startsWith('.')) {
            dependencies.add(depMatch[1])
          }
        })
      } catch (error) {
        logger.warn(`Failed to extract dependencies from ${file}`, error instanceof Error ? error : new Error(String(error)))
      }
    }

    return Array.from(dependencies)
  }

  /**
   * Create fallback coverage analysis when main analysis fails
   */
  private async createFallbackCoverageAnalysis(): Promise<CoverageAnalysisResult> {
    return {
      overall: {
        lines: { total: 0, covered: 0, uncovered: 0, percentage: 0 },
        functions: { total: 0, covered: 0, uncovered: 0, percentage: 0 },
        branches: { total: 0, covered: 0, uncovered: 0, percentage: 0 },
        statements: { total: 0, covered: 0, uncovered: 0, percentage: 0 }
      },
      files: [],
      gapAnalysis: {
        totalGaps: 0,
        criticalGaps: 0,
        highPriorityFiles: [],
        suggestedTests: [],
        coverageGoals: {
          currentOverall: 0,
          targetOverall: 80,
          improveBy: 80
        }
      },
      recommendations: [],
      trends: {
        coverageChange: 0,
        qualityScore: 50,
        testHealthScore: 50
      },
      timestamp: new Date().toISOString(),
      version: '1.0.0'
    }
  }

  /**
   * Adapt new coverage analysis format to legacy format
   */
  private adaptCoverageForLegacy(analysis: CoverageAnalysisResult): any {
    return {
      lines: analysis.overall.lines.percentage,
      functions: analysis.overall.functions.percentage,
      branches: analysis.overall.branches.percentage,
      statements: analysis.overall.statements.percentage,
      files: analysis.files.reduce((acc: any, file) => {
        acc[file.path] = {
          lines: { percentage: file.metrics.lines.percentage },
          functions: { percentage: file.metrics.functions.percentage },
          branches: { percentage: file.metrics.branches.percentage },
          statements: { percentage: file.metrics.statements.percentage }
        }
        return acc
      }, {})
    }
  }

  /**
   * Extract gaps from new coverage analysis for legacy format
   */
  private extractGapsFromAnalysis(analysis: CoverageAnalysisResult): any[] {
    return analysis.files
      .filter(file => file.priority === 'high')
      .map(file => ({
        file: file.path,
        uncoveredLines: file.uncoveredLines,
        missingFunctions: file.uncoveredFunctions,
        suggestedTests: [`Test ${file.uncoveredFunctions.length} uncovered functions`]
      }))
  }
}

export type { 
  TestWorkflowContext, 
  TestAnalysisResult, 
  TestGenerationRequest, 
  TestGenerationResult 
}